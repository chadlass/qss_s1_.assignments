{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2: part one\n",
    "\n",
    "Total points: 20\n",
    "\n",
    "Fraction of problem set two points: 25\\%\n",
    "\n",
    "**Concepts**: here, you're going to start using the SIP H-2A employer jobs and debarment data to practice exact matching,  regex, and fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import recordlinkage\n",
    "\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regex and exact matching (8 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Load data on debarments and job postings (0 points)\n",
    "\n",
    "Load the following datasets stored in `pset2_part1_inputdata`\n",
    "    \n",
    "- Historical H2A debarments (debar.csv); call this `debar`\n",
    "- Q1 2021 H2A job postings (jobs.csv); call this `jobs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "debar = pd.read_csv(\"debar.csv\")\n",
    "jobs = pd.read_csv(\"jobs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Try exact merge on business name  (2 points)\n",
    "\n",
    "- Use the `EMPLOYER_NAME` field of jobs\n",
    "- Use the `Name` field of debar\n",
    "\n",
    "A. Use pd.merge with an inner join on those fields to see whether there are any exact matches. \n",
    "\n",
    "B. If there are matches, print the name in each dataset, date range of debarment (`Start date` and `End date` in `debar`) and location from each data (`City, State` in `debar` and `EMPLOYER_CITY` and `EMPLOYER_STATE` in `jobs`)\n",
    "\n",
    "**Resources**:\n",
    "    - Slides 17-19 here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/slides/qss20_s21_class4.pdf \n",
    "    - Code here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/03_merging_session1.ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name   EMPLOYER_NAME Start date   End date       City, State  \\\n",
      "0  Rafael Barajas  Rafael Barajas  9/23/2016  9/22/2017  Sebring, Florida   \n",
      "\n",
      "    EMPLOYER_CITY EMPLOYER_STATE  \n",
      "0  Port St. Lucie             FL  \n"
     ]
    }
   ],
   "source": [
    "#debar.head()\n",
    "#jobs.head()\n",
    "\n",
    "merged = pd.merge(left = debar, right = jobs, how = \"inner\", left_on = \"Name\", right_on = \"EMPLOYER_NAME\")\n",
    "print(merged[[\"Name\", \"EMPLOYER_NAME\", \"Start date\", \"End date\", \"City, State\", \"EMPLOYER_CITY\", \"EMPLOYER_STATE\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Targeted regex\n",
    "\n",
    "You want to see if you can increase the exact match rate with some basic cleaning of each \n",
    "of the name fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Converting to upper (2 points)\n",
    "\n",
    "A. Convert the names `EMPLOYER_NAME` and `Name` to uppercase using list comprehension rather than df.varname.str.upper()\n",
    "\n",
    "B. Print a random sample of 15 values of each result\n",
    "\n",
    "C. Assign them back to the original data, writing over the original columns\n",
    "\n",
    "**Resources**:\n",
    "    - `new_colnames` line of code here for example of list comprehension: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/04_basicregex_formerging.ipynb\n",
    "    - Sampling from a list without replacement using the `random` module: https://note.nkmk.me/en/python-random-choice-sample-choices/ \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MYRKA MIREYA CARDENAS', 'YOLANDA CHAVEZ', 'OLD TREE FARMS/VERPAALEN CUSTOM SERVICE', 'LANDMARK LANDSCAPING', 'SAXTONS RIVER ORCHARDS, INC.', 'ROLLO FARM LABOR CONTRACTOR', 'VERN STRATTON FARMS', 'LABATTE FARMS', 'SRT FARMS', 'F&W FARMS', 'ANNABELLA LAND & CATTLE', 'DOVE CREEK FARMS', 'ANTON FERTILIZER INC.', 'SRT FARMS', 'OLD TREE FARMS/VERPAALEN CUSTOM SERVICE']\n",
      "['CITRUS HARVESTING, INC.', 'TOP NOTCH PORK, LLC', 'ROJAS AND SIMON HARVESTING, LLC', 'WESTERN RANGE ASSOCIATION', 'WESLEY BLADOW', 'JEFFREY L. MANUEL', 'SESTER FARMS, INC', 'CITRUS HARVESTING, INC.', 'WESTERN RANGE ASSOCIATION', 'EAM HARVESTING LLC', 'STROOPE BEE COMPANY, LLC', 'ALCO HARVESTING, LLC', 'HUMPHREY COKER SEED CO', 'FAMILY FRESH HARVESTING LLC', 'AG LABOR LLC']\n"
     ]
    }
   ],
   "source": [
    "debar[\"Name\"] = [name.upper() for name in debar[\"Name\"]]\n",
    "jobs[\"EMPLOYER_NAME\"] = [name.upper() for name in jobs[\"EMPLOYER_NAME\"]]\n",
    "\n",
    "print(random.sample(list(debar[\"Name\"]), 15))\n",
    "print(random.sample(list(jobs[\"EMPLOYER_NAME\"]), 15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Cleaning up punctuation (4 points)\n",
    "\n",
    "You notice that INC, CO, and LLC are sometimes followed by a . but sometimes not\n",
    "\n",
    "A. For each dataset, write a regex pattern to remove the . but only if it's preceded by INC, LLC, or CO \n",
    "\n",
    "Make sure LLC, INC, CO remain part of the string but just without the dot\n",
    "\n",
    "B. Test the pattern on the positive and negative example and print the result. The first positive example should return `CISCO PRODUCE INC`; the second positive example should return `AVOYELLES HONEY CO, LLC` the negative example should return `E.V. RANCH LLP` (so leave the dots between E.V. in)\n",
    "\n",
    "C. Execute on (1) Name in `debar` (can just write over the col) and (3) EMPLOYER_NAME  in `jobs`, making sure to use the uppercase versions of the variables\n",
    "\n",
    "**Hint**: https://stackoverflow.com/questions/7191209/python-re-sub-replace-with-matched-content\n",
    "\n",
    "**Resources**:\n",
    "    - Regex slides are 22-40: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/slides/qss20_s21_class4.pdf \n",
    "    - Regex code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/04_basicregex_formerging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example_1 = \"CISCO PRODUCE INC.\"\n",
    "pos_example_2 = \"AVOYELLES HONEY CO., LLC\"\n",
    "neg_example = \"E.V. RANCH LLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CISCO PRODUCE INC AVOYELLES HONEY CO, LLC E.V. RANCH LLP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                     J&J HARVESTING\n",
       "1             STAHLMAN APIARIES, INC\n",
       "2                      TRUST NURSERY\n",
       "3               ANTON FERTILIZER INC\n",
       "4    GREAT PLAINS FLUID SERVICE, INC\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    FAZIO FARMS OPERATING COMPANY, LLC\n",
       "1                    CHARLIE SUNDERLAND\n",
       "2                     MICHAEL RUDEBUSCH\n",
       "3                          LODAHL FARMS\n",
       "4                DUNSON HARVESTING, INC\n",
       "Name: EMPLOYER_NAME, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Regex for punctuation removal\n",
    "company_regex = r'(?<=INC)\\.|(?<=LLC)\\.|(?<=CO)\\.'\n",
    "\n",
    "#test it out\n",
    "test_1 = re.sub(company_regex, '', pos_example_1)\n",
    "test_2 = re.sub(company_regex, '', pos_example_2)\n",
    "test_3 = re.sub(company_regex, '', neg_example)\n",
    "print(test_1, test_2, test_3)\n",
    "\n",
    "# apply using list comprehension\n",
    "debar[\"Name\"] = [re.sub(company_regex, \"\", company_name) for company_name in debar[\"Name\"]]\n",
    "jobs[\"EMPLOYER_NAME\"] = [re.sub(company_regex, \"\", company_name) for company_name in jobs[\"EMPLOYER_NAME\"]]\n",
    "\n",
    "#check\n",
    "debar.Name.head()\n",
    "jobs.EMPLOYER_NAME.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 OPTIONAL extra credit - regex to separate companies from individuals (2 points)\n",
    "\n",
    "You notice some employers in `debar` have both the name of the company and the name of individual, e.g.:\n",
    "    \n",
    "COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\n",
    "\n",
    "Use the uppercase/cleaned version of the Name in `debar`\n",
    "\n",
    "A. Write a regex pattern that does the following:\n",
    "    - Captures the pattern that occurs before COMPANY if (COMPANY) is in string-- so in above, extracts COUNTY FAIR FARM \n",
    "    - Captures the pattern that occurs before INDIVIDUAL if (INDIVIDUAL) is also in string -- so in above, extracts ANDREW WILLIAMSON (so omit the and)\n",
    "    \n",
    "B. Test the pattern on `pos_example` and `neg_example`-- make sure former returns a list (if using find.all) or match object (if using re.search) with the company name and individual name separated out; make sure latter returns empty\n",
    "    \n",
    "C. Iterate over the cleaned `Name` column in debar and execute the regex. Use it to create two new columns in debar:\n",
    "    - A column for company (full Name string if left as is; pattern before COMPANY if one extracted)\n",
    "    - A column for individual (full Name string if left as is; pattern before INDIVIDUAL if one extracted)\n",
    "    \n",
    "D. Print those columns for the rows containing the negative example and positive example\n",
    "\n",
    "**Hint**: for step A, you can either use re.search, re.match, or re.findall; don't worry about matching B&R Harvesting and Paul Cruz (Individual)\n",
    "\n",
    "For step C, you probably want to use a loop or function that uses if else to do different things if a match is found or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example = \"COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\"\n",
    "neg_example = \"CISCO PRODUCE INC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Fuzzy matching to match debarments to jobs (12 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Preprocessing location (2 points)\n",
    "\n",
    "You want to block on state but notice that states in `debar` have a mix of two digit codes and full state names (e.g., GA versus Georgia) while states in `jobs` are all two-digit codes\n",
    "\n",
    "A. Run the code below to load the `states` crosswalk. Use that crosswalk to create a field in `debar` that has the two-digit state abbreviation for all locations (hint: you may need to first split the string on the \", \" or use str.replace to extract the state)\n",
    "\n",
    "B. Use an `assert` statement to check that all the states in `debar` are two-digits after the cleaning\n",
    "\n",
    "**Notes**: you can filter out states that are NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GA          19\n",
       "TX          18\n",
       "KS          10\n",
       "FL          10\n",
       "UT           6\n",
       "KY           5\n",
       "SD           5\n",
       "CA           4\n",
       "CO           3\n",
       "NY           3\n",
       "LA           3\n",
       "AR           3\n",
       "ND           3\n",
       "Dakota       3\n",
       "MA           3\n",
       "MT           2\n",
       "OK           2\n",
       "ID           2\n",
       "VT           1\n",
       "ME           1\n",
       "MD           1\n",
       "Carolina     1\n",
       "MN           1\n",
       "SC           1\n",
       "IL           1\n",
       "TN           1\n",
       "AK           1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-4d8d4e71e873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdebar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## code to load state crosswalk\n",
    "## source- https://towardsdatascience.com/state-name-to-state-abbreviation-crosswalks-6936250976c\n",
    "\n",
    "\n",
    "states = pd.read_csv(\"states_pset2.csv\")\n",
    "#states.head()\n",
    "\n",
    "#get so the city, state column into a better name so it can be manipulated\n",
    "debar.rename(columns={'City, State':'cityandstate'}, inplace=True)\n",
    "\n",
    "#clear NA's\n",
    "debar = debar.replace('nan', np.nan)\n",
    "debar = debar.dropna(how = 'any')\n",
    "\n",
    "#Use regex's to split up city and state into their own columns\n",
    "debar[\"city\"] = debar[\"cityandstate\"].replace(\"\\,.*\",\"\", regex = True)\n",
    "debar[\"state\"] = debar[\"cityandstate\"].replace(\".*\\\\s\", \"\", regex = True)\n",
    "\n",
    "#Iterate through the frame to see if we have an appropriate state code. If not,\n",
    "#matches state full name into states dataframe and replaces with associated monicker.\n",
    "for i in range(0, debar[\"state\"].shape[0]):\n",
    "    check = debar[\"state\"].iloc[i]\n",
    "    if len(check) != 2:\n",
    "        for j in range(0, states[\"Description\"].shape[0]):\n",
    "            if check == states[\"Description\"].iloc[j]:\n",
    "                debar[\"state\"].iloc[i] = states[\"Code\"].iloc[j]\n",
    "                \n",
    "debar[\"state\"].value_counts()\n",
    "\n",
    "assert all(debar.state.str.len() == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#same rename process with a different removal process for NA\n",
    "jobs.rename(columns={'EMPLOYER_POC_STATE':'state'}, inplace=True)\n",
    "jobs = jobs[~jobs.state.isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop duplicates\n",
    "jobs = jobs.drop_duplicates(subset= [\"EMPLOYER_NAME\"])\n",
    "debar = debar.drop_duplicates(subset = [\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 step by step fuzzy matching (4 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Write fuzzy matching code (don't yet put inside a user-defined function) that:\n",
    "\n",
    "- Blocks on two-digit state code\n",
    "- Finds matches based on similarity between the employer name (`Name`) in `debar` (uppercase and cleaned) and `EMPLOYER_NAME` in `jobs` (uppercase and cleaned). You can choose which distance metric and threshold to use (feel free to set a threshold low enough to get some matches even if that leads to some false positives).\n",
    "\n",
    "For the steps after compute, just take any match with non-zero value rather than using a classifier (so skip the k-means or e-m step in the example code)\n",
    "\n",
    "B. Print the matches and comment on examples of ones that seem like true positives and ones that seem like false matches\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Solutions code here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/05_merging_session2_activitysolutions.ipynb \n",
    "- Example code here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/05_merging_session2_codeexample.ipynb\n",
    "\n",
    "\n",
    "**Hint**: you may need to deduplicate multiple records in the datasets for the recordlinkage package to work. See drop_duplicates within pandas and subset command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pyjarowinkler import distance\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>RECEIVED_DATE</th>\n",
       "      <th>DECISION_DATE</th>\n",
       "      <th>TYPE_OF_EMPLOYER_APPLICATION</th>\n",
       "      <th>H2A_LABOR_CONTRACTOR</th>\n",
       "      <th>NATURE_OF_TEMPORARY_NEED</th>\n",
       "      <th>EMERGENCY_FILING</th>\n",
       "      <th>EMPLOYER_NAME</th>\n",
       "      <th>TRADE_NAME_DBA</th>\n",
       "      <th>...</th>\n",
       "      <th>ADDENDUM_B_HOUSING_ATTACHED</th>\n",
       "      <th>TOTAL_HOUSING_RECORDS</th>\n",
       "      <th>MEALS_PROVIDED</th>\n",
       "      <th>MEALS_CHARGED</th>\n",
       "      <th>MEAL_REIMBURSEMENT_MINIMUM</th>\n",
       "      <th>MEAL_REIMBURSEMENT_MAXIMUM</th>\n",
       "      <th>PHONE_TO_APPLY</th>\n",
       "      <th>EMAIL_TO_APPLY</th>\n",
       "      <th>WEBSITE_TO_APPLY</th>\n",
       "      <th>TOTAL_ADDENDUM_A_RECORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H-300-20199-721302</td>\n",
       "      <td>Determination Issued - Withdrawn</td>\n",
       "      <td>2020-07-17 14:50:40.840</td>\n",
       "      <td>2020-10-01 00:00:00.000</td>\n",
       "      <td>Individual Employer</td>\n",
       "      <td>N</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>Y</td>\n",
       "      <td>FAZIO FARMS OPERATING COMPANY, LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>12.68</td>\n",
       "      <td>12.68</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13607017661</td>\n",
       "      <td>faziofarms@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H-300-20231-773906</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>2020-08-20 10:38:15.620</td>\n",
       "      <td>2020-10-01 00:00:00.000</td>\n",
       "      <td>Association - Agent</td>\n",
       "      <td>N</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>CHARLIE SUNDERLAND</td>\n",
       "      <td>Panter &amp; Sunderland Nursery</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.68</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19318083783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.jobs4tn.gov/vosnet/Default.aspx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H-300-20231-774123</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>2020-08-24 15:33:14.340</td>\n",
       "      <td>2020-10-01 00:00:00.000</td>\n",
       "      <td>Individual Employer</td>\n",
       "      <td>N</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>MICHAEL RUDEBUSCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.68</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19369333827</td>\n",
       "      <td>fayethlynpitre@rocketmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H-300-20231-774151</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>2020-08-21 12:08:09.760</td>\n",
       "      <td>2020-10-01 00:00:00.000</td>\n",
       "      <td>Individual Employer</td>\n",
       "      <td>N</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>LODAHL FARMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.68</td>\n",
       "      <td>55.0</td>\n",
       "      <td>14069637560</td>\n",
       "      <td>lodahl_kelsey@yahoo.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H-300-20231-774508</td>\n",
       "      <td>Determination Issued - Certification</td>\n",
       "      <td>2020-08-20 10:17:34.530</td>\n",
       "      <td>2020-10-01 00:00:00.000</td>\n",
       "      <td>Individual Employer</td>\n",
       "      <td>Y</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>DUNSON HARVESTING, INC</td>\n",
       "      <td>Dunson Harvesting, Inc.</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>8</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.68</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18632939888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.employflorida.com</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CASE_NUMBER                           CASE_STATUS  \\\n",
       "0  H-300-20199-721302      Determination Issued - Withdrawn   \n",
       "1  H-300-20231-773906  Determination Issued - Certification   \n",
       "2  H-300-20231-774123  Determination Issued - Certification   \n",
       "3  H-300-20231-774151  Determination Issued - Certification   \n",
       "4  H-300-20231-774508  Determination Issued - Certification   \n",
       "\n",
       "             RECEIVED_DATE            DECISION_DATE  \\\n",
       "0  2020-07-17 14:50:40.840  2020-10-01 00:00:00.000   \n",
       "1  2020-08-20 10:38:15.620  2020-10-01 00:00:00.000   \n",
       "2  2020-08-24 15:33:14.340  2020-10-01 00:00:00.000   \n",
       "3  2020-08-21 12:08:09.760  2020-10-01 00:00:00.000   \n",
       "4  2020-08-20 10:17:34.530  2020-10-01 00:00:00.000   \n",
       "\n",
       "  TYPE_OF_EMPLOYER_APPLICATION H2A_LABOR_CONTRACTOR NATURE_OF_TEMPORARY_NEED  \\\n",
       "0          Individual Employer                    N                 Seasonal   \n",
       "1          Association - Agent                    N                 Seasonal   \n",
       "2          Individual Employer                    N                 Seasonal   \n",
       "3          Individual Employer                    N                 Seasonal   \n",
       "4          Individual Employer                    Y                 Seasonal   \n",
       "\n",
       "  EMERGENCY_FILING                       EMPLOYER_NAME  \\\n",
       "0                Y  FAZIO FARMS OPERATING COMPANY, LLC   \n",
       "1                N                  CHARLIE SUNDERLAND   \n",
       "2                N                   MICHAEL RUDEBUSCH   \n",
       "3                N                        LODAHL FARMS   \n",
       "4                N              DUNSON HARVESTING, INC   \n",
       "\n",
       "                TRADE_NAME_DBA  ... ADDENDUM_B_HOUSING_ATTACHED  \\\n",
       "0                          NaN  ...                           N   \n",
       "1  Panter & Sunderland Nursery  ...                           N   \n",
       "2                          NaN  ...                           N   \n",
       "3                          NaN  ...                           Y   \n",
       "4      Dunson Harvesting, Inc.  ...                           Y   \n",
       "\n",
       "  TOTAL_HOUSING_RECORDS MEALS_PROVIDED MEALS_CHARGED  \\\n",
       "0                     1              Y         12.68   \n",
       "1                     1              N           NaN   \n",
       "2                     1              N           NaN   \n",
       "3                     2              N           NaN   \n",
       "4                     8              N           NaN   \n",
       "\n",
       "  MEAL_REIMBURSEMENT_MINIMUM MEAL_REIMBURSEMENT_MAXIMUM PHONE_TO_APPLY  \\\n",
       "0                      12.68                       55.0    13607017661   \n",
       "1                      12.68                       55.0    19318083783   \n",
       "2                      12.68                       55.0    19369333827   \n",
       "3                      12.68                       55.0    14069637560   \n",
       "4                      12.68                       55.0    18632939888   \n",
       "\n",
       "                  EMAIL_TO_APPLY                             WEBSITE_TO_APPLY  \\\n",
       "0           faziofarms@gmail.com                                          NaN   \n",
       "1                            NaN  https://www.jobs4tn.gov/vosnet/Default.aspx   \n",
       "2  fayethlynpitre@rocketmail.com                                          NaN   \n",
       "3        lodahl_kelsey@yahoo.com                                          NaN   \n",
       "4                            NaN                        www.employflorida.com   \n",
       "\n",
       "   TOTAL_ADDENDUM_A_RECORDS  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90    RUBEN RUIZ (DESOTO HARVESTING)\n",
       "11             LOEWEN HARVESTING LLC\n",
       "76                  ROBERT D. TOWLES\n",
       "20              SLASH E.V. RANCH LLP\n",
       "83                 CIRA CORTEZ LOPEZ\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Index>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Compare>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Compare>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">46</th>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "0  16  0.0  1.0\n",
       "   23  0.0  1.0\n",
       "   40  0.0  1.0\n",
       "   42  0.0  1.0\n",
       "11 16  0.0  1.0\n",
       "...    ...  ...\n",
       "49 45  0.0  1.0\n",
       "46 7   0.0  1.0\n",
       "   21  0.0  1.0\n",
       "   33  0.0  1.0\n",
       "   37  0.0  1.0\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   debar_index  jobs_index\n",
      "0           44          49\n",
      "1           48          49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debar_index</th>\n",
       "      <th>jobs_index</th>\n",
       "      <th>Name</th>\n",
       "      <th>state_debar</th>\n",
       "      <th>EMPLOYER_NAME</th>\n",
       "      <th>state_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>PETER PETERS</td>\n",
       "      <td>TX</td>\n",
       "      <td>ETTER FARMS</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>DOVE CREEK FARMS</td>\n",
       "      <td>TX</td>\n",
       "      <td>ETTER FARMS</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debar_index  jobs_index              Name state_debar EMPLOYER_NAME  \\\n",
       "0           44          49      PETER PETERS          TX   ETTER FARMS   \n",
       "1           48          49  DOVE CREEK FARMS          TX   ETTER FARMS   \n",
       "\n",
       "  state_jobs  \n",
       "0         TX  \n",
       "1         TX  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debar_samp = debar.sample(n = 50, random_state = 556)\n",
    "jobs_samp = jobs.sample(n = 50, random_state = 556)\n",
    "\n",
    "debar_samp[\"Name\"].head()\n",
    "## create blocker\n",
    "link_debar_jobs = recordlinkage.Index()\n",
    "\n",
    "debar_samp = debar_samp.reset_index()\n",
    "jobs_samp = jobs_samp.reset_index()\n",
    "##block on state code\n",
    "link_debar_jobs.block(\"state\")\n",
    "\n",
    "#compute candidate links\n",
    "candidate_links_state = link_debar_jobs.index(debar_samp, jobs_samp)\n",
    "\n",
    "#compare class creation\n",
    "compare = recordlinkage.Compare()\n",
    "compare.string('Name', 'EMPLOYER_NAME', method = 'jarowinkler', threshold = 0.7)\n",
    "compare.string('state', 'state', method = 'jarowinkler', threshold = 0.7)\n",
    "\n",
    "#Feed candidate links to the compare class and compute\n",
    "compare_vectors = compare.compute(candidate_links_state, debar_samp, jobs_samp)\n",
    "compare_vectors \n",
    "               \n",
    "## see under the hood steps to modif \n",
    "\n",
    "ecm = recordlinkage.ECMClassifier()\n",
    "predicted_matches_ecm = pd.DataFrame(list(ecm.fit_predict(compare_vectors)), columns = [\"debar_index\", \"jobs_index\"])\n",
    "\n",
    "print(predicted_matches_ecm)\n",
    "\n",
    "debar_samp['debar_index'] = debar_samp.index\n",
    "\n",
    "m1_add_debar = pd.merge(predicted_matches_ecm, debar_samp[[\"Name\", \"debar_index\", \"state\"]], on = \"debar_index\", how = \"inner\")\n",
    "\n",
    "jobs_samp[\"jobs_index\"] = jobs_samp.index\n",
    "m2_add_jobs = pd.merge(m1_add_debar, jobs_samp[[\"EMPLOYER_NAME\", \"jobs_index\", \"state\"]], \n",
    "                       on = \"jobs_index\", how = \"inner\", suffixes = [\"_debar\", \"_jobs\"])\n",
    "m2_add_jobs\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neither of these seem to be exact matches. Frustrating, certainly. \n",
    "#I have also tried ramping the filter down to a 50% threshold, and the matches are even less certain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 write a fuzzy matching function (6 points)\n",
    "\n",
    "You want to see how the matches change if you add the town and not only state as a field and also want to automate the process of matching a bit to try different distance thresholds.\n",
    "\n",
    "A. Extract the City from the `City, State` column of debar\n",
    "\n",
    "B. Convert that new `city` column to uppercase and convert the `EMPLOYER_CITY` column in jobs to uppercase\n",
    "\n",
    "C. Write a function surrounding the code in `recordlinkage` (so you don't need to recode the package from scratch) that (1) takes in each dataset, (2) blocks on two-digit state, and (3) fuzzy matches on employer name and employer city\n",
    "\n",
    "D. Execute the function with a couple different string distance thresholds and print the results of each\n",
    "\n",
    "5 out of 6 points: function takes arguments for input datasets, varname to block on, two varnames to fuzzy match on, string distance function, and string distance threshold\n",
    "    \n",
    "6 out of 6: above but function is also general enough that it takes a variable # of strings to match on--- so should work if you either execute just using employer name or also work if you execute using employer name and employer city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Already created a city column above for part A \n",
    "\n",
    "## city to upper\n",
    "\n",
    "debar[\"city\"] = [city.upper() for city in debar[\"city\"]]\n",
    "\n",
    "def matcher(df1, df2, block, fuz1, fuz2, distance, thresh):\n",
    "    df1_samp = df1.sample(n = 50, random_state = 556)\n",
    "    df2_samp = df2.sample(n = 50, random_state = 556)\n",
    "    \n",
    "    linker = recordlinkage.Index()\n",
    "\n",
    "    df1_samp = df1_samp.reset_index()\n",
    "    df2_samp = df2_samp.reset_index()\n",
    "    ##block on state code\n",
    "    link_debar_jobs.block(block)\n",
    "    \n",
    "    candidate_links_state = linker.index(df1_samp, df2_samp)\n",
    "\n",
    "#compare class creation\n",
    "    compare = recordlinkage.Compare()\n",
    "    compare.string(fuz1, fuz1, method = 'jarowinkler', threshold = thresh)\n",
    "    compare.string(fuz2, fuz2, method = 'jarowinkler', threshold = thresh)\n",
    "    \n",
    "    compare_vectors = compare.compute(candidate_links_state, df1_samp, df2_samp)\n",
    "    \n",
    "    ecm = recordlinkage.ECMClassifier()\n",
    "    predicted_matches_ecm = pd.DataFrame(list(ecm.fit_predict(compare_vectors)), columns = [\"df1_index\", \"df2_index\"])\n",
    "    \n",
    "    \n",
    "    df1_samp['df1_index'] = df1_samp.index\n",
    "\n",
    "    m1_add_df1 = pd.merge(predicted_matches_ecm, df1_samp[[\"Name\", \"df1_index\", \"state\", \"city\"]], on = \"df1_index\", how = \"inner\")\n",
    "\n",
    "\n",
    "    df2_samp[\"df2_index\"] = df2_samp.index\n",
    "    m2_add_df2 = pd.merge(m1_add_df1, df2_samp[[\"EMPLOYER_NAME\", \"df2_index\", \"state\", \"city\"]], \n",
    "                       on = \"df2_index\", how = \"inner\", suffixes = [\"_df1\", \"_df2\"])\n",
    "\n",
    "    return m2_add_jobs\n",
    "                   \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
